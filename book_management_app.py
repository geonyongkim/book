import streamlit as st
import pandas as pd
import uuid
import requests
import urllib.parse
from PIL import Image, ImageEnhance
from pyzbar.pyzbar import decode
from datetime import datetime, timedelta
import plotly.express as px

# [Google Sheets ì—°ë™ ë¼ì´ë¸ŒëŸ¬ë¦¬]
import gspread
from google.oauth2.service_account import Credentials

# --- [ì„¤ì •] ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì´ë¦„ ---
# Google ìŠ¤í”„ë ˆë“œì‹œíŠ¸ íŒŒì¼ ì´ë¦„ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
SHEET_NAME = "english_library_data" 

# --- [ë°˜ì‘ ì˜µì…˜ ì •ì˜] ---
REACTION_OPTIONS = ["ì„ íƒ ì•ˆ í•¨", "ğŸ˜„ ì¬ë¯¸ìˆì–´ìš”", "ğŸ˜“ ì–´ë ¤ì›Œìš”", "ğŸ¨ ê·¸ë¦¼ì´ ë§ˆìŒì— ë“¤ì–´ìš”", "ğŸ£ ìŠ¤ìŠ¤ë¡œ ì½ì„ ìˆ˜ ìˆì–´ìš”"]

# --- [í•¨ìˆ˜ 1] êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ---
# ìºì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë§¤ë²ˆ ì¬ì—°ê²°í•˜ì§€ ì•Šë„ë¡ í•¨
@st.cache_resource
def get_google_sheet_client():
    # secrets.tomlì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    scopes = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ]
    credentials = Credentials.from_service_account_info(
        st.secrets["gcp_service_account"],
        scopes=scopes
    )
    client = gspread.authorize(credentials)
    return client

# --- [í•¨ìˆ˜ 2] ë°ì´í„° ë¡œë“œ (Google Sheets -> DataFrame) ---
def load_data():
    client = get_google_sheet_client()
    try:
        sh = client.open(SHEET_NAME)
    except gspread.exceptions.SpreadsheetNotFound:
        st.error(f"êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ '{SHEET_NAME}' ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ ê³„ì •ì— ê³µìœ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    # 1. Books ë°ì´í„° ë¡œë“œ
    try:
        wks_books = sh.worksheet("books")
        data_books = wks_books.get_all_records()
        books_df = pd.DataFrame(data_books)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ì´ˆê¸°í™”
        required_cols = ['ID', 'ì œëª©', 'ISBN', 'ë ˆë²¨', 'ì½ì€íšŸìˆ˜', 'ìƒíƒœ', 'ë°˜ì‘', 'í‘œì§€URL']
        if books_df.empty:
            books_df = pd.DataFrame(columns=required_cols)
        else:
            # ì»¬ëŸ¼ì´ ë¶€ì¡±í•˜ë©´ ì±„ì›Œë„£ê¸°
            for col in required_cols:
                if col not in books_df.columns:
                    books_df[col] = ""
            # NaN ì²˜ë¦¬
            books_df['ë°˜ì‘'] = books_df['ë°˜ì‘'].replace("", "ì„ íƒ ì•ˆ í•¨").fillna("ì„ íƒ ì•ˆ í•¨")
            books_df['ISBN'] = books_df['ISBN'].astype(str)
            
    except gspread.exceptions.WorksheetNotFound:
        # ì‹œíŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„± (í—¤ë” ì¶”ê°€)
        wks_books = sh.add_worksheet(title="books", rows=100, cols=10)
        wks_books.append_row(['ID', 'ì œëª©', 'ISBN', 'ë ˆë²¨', 'ì½ì€íšŸìˆ˜', 'ìƒíƒœ', 'ë°˜ì‘', 'í‘œì§€URL'])
        books_df = pd.DataFrame(columns=['ID', 'ì œëª©', 'ISBN', 'ë ˆë²¨', 'ì½ì€íšŸìˆ˜', 'ìƒíƒœ', 'ë°˜ì‘', 'í‘œì§€URL'])

    # 2. Logs ë°ì´í„° ë¡œë“œ
    try:
        wks_logs = sh.worksheet("logs")
        data_logs = wks_logs.get_all_records()
        logs_df = pd.DataFrame(data_logs)
        
        if logs_df.empty:
            logs_df = pd.DataFrame(columns=['ë‚ ì§œ', 'ì±…ID', 'ì œëª©', 'ë ˆë²¨'])
        else:
             # ë‚ ì§œ í˜•ì‹ ë³€í™˜
            logs_df['ë‚ ì§œ'] = pd.to_datetime(logs_df['ë‚ ì§œ'])
            
    except gspread.exceptions.WorksheetNotFound:
        wks_logs = sh.add_worksheet(title="logs", rows=100, cols=5)
        wks_logs.append_row(['ë‚ ì§œ', 'ì±…ID', 'ì œëª©', 'ë ˆë²¨'])
        logs_df = pd.DataFrame(columns=['ë‚ ì§œ', 'ì±…ID', 'ì œëª©', 'ë ˆë²¨'])

    return books_df, logs_df

# --- [í•¨ìˆ˜ 3] ë°ì´í„° ì €ì¥ (DataFrame -> Google Sheets) ---
def save_books(df):
    client = get_google_sheet_client()
    sh = client.open(SHEET_NAME)
    wks = sh.worksheet("books")
    
    # ë°ì´í„°í”„ë ˆì„ ë‚´ìš©ìœ¼ë¡œ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ (ì „ì²´ ë®ì–´ì“°ê¸° ë°©ì‹ì´ ì•ˆì „í•¨)
    # 1. í—¤ë” ì¤€ë¹„
    header = df.columns.values.tolist()
    # 2. ë°ì´í„° ì¤€ë¹„ (NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì•¼ API ì˜¤ë¥˜ ë°©ì§€)
    data = df.fillna("").values.tolist()
    
    # 3. ì‹œíŠ¸ í´ë¦¬ì–´ í›„ ì—…ë°ì´íŠ¸
    wks.clear()
    wks.update(range_name='A1', values=[header] + data)

# --- [í•¨ìˆ˜ 4] ë¡œê·¸ ì¶”ê°€ (Append Row) ---
def add_log(book_id, title, level):
    client = get_google_sheet_client()
    sh = client.open(SHEET_NAME)
    wks = sh.worksheet("logs")
    
    # ë‚ ì§œ ë¬¸ìì—´ ë³€í™˜
    today_str = datetime.now().strftime("%Y-%m-%d")
    
    # í–‰ ì¶”ê°€
    wks.append_row([today_str, str(book_id), str(title), int(level)])

# --- [í•¨ìˆ˜ 5] ë°”ì½”ë“œ ìŠ¤ìº” (ì¤Œ & ë³´ì •) ---
def scan_barcode(image_file):
    try:
        image = Image.open(image_file)
        attempts = [
            image.convert('L'), 
            image.convert('L').crop((image.size[0]*0.2, image.size[1]*0.2, image.size[0]*0.8, image.size[1]*0.8)),
            ImageEnhance.Sharpness(image.convert('L').crop((image.size[0]*0.35, image.size[1]*0.35, image.size[0]*0.65, image.size[1]*0.65))).enhance(2.0)
        ]
        for img in attempts:
            decoded = decode(img)
            for obj in decoded: return obj.data.decode("utf-8")
    except Exception: pass
    return None

# --- [í•¨ìˆ˜ 6] ë„ì„œ ê²€ìƒ‰ ---
def search_book_info(isbn):
    if not isbn: return None, None
    clean_isbn = str(isbn).strip().replace("-", "").replace(" ", "")
    try:
        r = requests.get(f"https://www.googleapis.com/books/v1/volumes?q=isbn:{clean_isbn}").json()
        if "items" in r:
            return r["items"][0]["volumeInfo"].get("title", ""), r["items"][0]["volumeInfo"].get("imageLinks", {}).get("thumbnail", "")
    except: pass
    try:
        r = requests.get(f"https://openlibrary.org/api/books?bibkeys=ISBN:{clean_isbn}&jscmd=data&format=json").json()
        if f"ISBN:{clean_isbn}" in r:
            bk = r[f"ISBN:{clean_isbn}"]
            cv = bk.get("cover", {})
            return bk.get("title", ""), (cv.get("medium") or cv.get("large") or cv.get("small", ""))
    except: pass
    return None, None

# =========================================================
# ë©”ì¸ UI
# =========================================================

st.set_page_config(page_title="ì•„ì´ ì˜ì–´ ë…ì„œ ë§¤ë‹ˆì € (Cloud)", layout="wide", page_icon="â˜ï¸")

# ë°ì´í„° ë¡œë“œ ì‹œ ìŠ¤í”¼ë„ˆ í‘œì‹œ
with st.spinner("êµ¬ê¸€ í´ë¼ìš°ë“œì™€ ë°ì´í„°ë¥¼ ë™ê¸°í™” ì¤‘ì…ë‹ˆë‹¤..."):
    books_df, logs_df = load_data()

st.title("ğŸ“š Smart English Library v3.0 (Cloud Sync)")
st.caption("ëª¨ë“  ë°ì´í„°ëŠ” êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì˜êµ¬ ì €ì¥ë©ë‹ˆë‹¤.")

tab1, tab2, tab3 = st.tabs(["ğŸ“Š ìƒì„¸ ëŒ€ì‹œë³´ë“œ", "ğŸ“– ì„œì¬ ê´€ë¦¬ (ì˜¤ë””ì˜¤/ìˆ˜ì •)", "â• ìƒˆ ì±… ë“±ë¡"])

# --- [íƒ­ 1] ìƒì„¸ ëŒ€ì‹œë³´ë“œ ---
with tab1:
    st.markdown("### ğŸ“ˆ ë…ì„œ í˜„í™© ë¸Œë¦¬í•‘")
    
    if logs_df.empty and books_df.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì±…ì„ ë“±ë¡í•˜ê³  ë…ì„œ ê¸°ë¡ì„ ì‹œì‘í•´ë³´ì„¸ìš”!")
    else:
        today = pd.Timestamp.now().normalize()
        this_month_start = today.replace(day=1)
        
        daily_reads = logs_df[logs_df['ë‚ ì§œ'] == today]
        month_reads = logs_df[logs_df['ë‚ ì§œ'] >= this_month_start]
        
        kpi1, kpi2, kpi3, kpi4 = st.columns(4)
        kpi1.metric("ì´ ë³´ìœ  ë„ì„œ", f"{len(books_df)}ê¶Œ")
        kpi2.metric("ì´ ëˆ„ì  ì½ê¸°", f"{len(logs_df)}íšŒ")
        kpi3.metric("ì´ë²ˆ ë‹¬ ë…ì„œ", f"{len(month_reads)}íšŒ")
        kpi4.metric("ì˜¤ëŠ˜ ì½ì€ ì±…", f"{len(daily_reads)}ê¶Œ")
        
        st.divider()
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.subheader("ğŸ—“ï¸ ìµœê·¼ 30ì¼ ë…ì„œ ì¶”ì´")
            if not logs_df.empty:
                last_30 = logs_df[logs_df['ë‚ ì§œ'] >= (today - timedelta(days=29))]
                daily_counts = last_30.groupby('ë‚ ì§œ').size().reset_index(name='ê¶Œìˆ˜')
                fig = px.bar(daily_counts, x='ë‚ ì§œ', y='ê¶Œìˆ˜', text_auto=True, color_discrete_sequence=['#4C78A8'])
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.write("ë°ì´í„° ë¶€ì¡±")

        with c2:
            st.subheader("ğŸ§¸ ì•„ì´ì˜ ë°˜ì‘ ë¶„ì„")
            if not books_df.empty:
                reaction_counts = books_df[books_df['ë°˜ì‘'] != 'ì„ íƒ ì•ˆ í•¨']['ë°˜ì‘'].value_counts().reset_index()
                reaction_counts.columns = ['ë°˜ì‘', 'ê¶Œìˆ˜']
                if not reaction_counts.empty:
                    fig2 = px.pie(reaction_counts, values='ê¶Œìˆ˜', names='ë°˜ì‘', hole=0.4, title="ë“±ë¡ëœ ì±…ì— ëŒ€í•œ ì•„ì´ ë°˜ì‘")
                    st.plotly_chart(fig2, use_container_width=True)
                else:
                    st.info("ì•„ì§ ì•„ì´ ë°˜ì‘ì´ ê¸°ë¡ëœ ì±…ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.write("ë°ì´í„° ë¶€ì¡±")

        st.divider()

        r1, r2 = st.columns(2)
        with r1:
            st.subheader("ğŸ† ë§ì´ ì½ì€ ì±… Top 5")
            if not books_df.empty:
                # ìˆ«ìí˜•ìœ¼ë¡œ í™•ì‹¤íˆ ë³€í™˜ í›„ ì •ë ¬
                books_df['ì½ì€íšŸìˆ˜'] = pd.to_numeric(books_df['ì½ì€íšŸìˆ˜'], errors='coerce').fillna(0)
                top_books = books_df.sort_values(by='ì½ì€íšŸìˆ˜', ascending=False).head(5)
                for idx, row in top_books.iterrows():
                    st.write(f"**{int(row['ì½ì€íšŸìˆ˜'])}íšŒ** | {row['ì œëª©']} (Lv.{row['ë ˆë²¨']})")
        
        with r2:
            st.subheader("ğŸ“š ë ˆë²¨ë³„ ë³´ìœ  í˜„í™©")
            if not books_df.empty:
                lvl_counts = books_df['ë ˆë²¨'].value_counts().sort_index()
                st.bar_chart(lvl_counts)

# --- [íƒ­ 2] ì„œì¬ ê´€ë¦¬ ---
with tab2:
    c_head, c_sort = st.columns([3, 2])
    with c_head: st.subheader("ë³´ìœ  ë„ì„œ ê´€ë¦¬")
    with c_sort:
        sort_option = st.selectbox("ğŸ“š ì •ë ¬ ê¸°ì¤€", ["ìµœì‹  ë“±ë¡ìˆœ", "ìì£¼ ì½ì€ ì±… (Best)", "ì•ˆ ì½ì€ ì±… (0íšŒ)", "ì•„ì´ ë°˜ì‘ë³„", "ë ˆë²¨ ë†’ì€ ìˆœ"])

    if not books_df.empty:
        # ë°ì´í„° íƒ€ì… ì •ë¦¬ (ì •ë ¬ ì˜¤ë¥˜ ë°©ì§€)
        books_df['ì½ì€íšŸìˆ˜'] = pd.to_numeric(books_df['ì½ì€íšŸìˆ˜'], errors='coerce').fillna(0)
        books_df['ë ˆë²¨'] = pd.to_numeric(books_df['ë ˆë²¨'], errors='coerce').fillna(1)

        display_df = books_df.copy()
        
        if sort_option == "ìµœì‹  ë“±ë¡ìˆœ": display_df = display_df.iloc[::-1]
        elif sort_option == "ìì£¼ ì½ì€ ì±… (Best)": display_df = display_df.sort_values(by='ì½ì€íšŸìˆ˜', ascending=False)
        elif sort_option == "ì•ˆ ì½ì€ ì±… (0íšŒ)": display_df = display_df.sort_values(by='ì½ì€íšŸìˆ˜', ascending=True)
        elif sort_option == "ì•„ì´ ë°˜ì‘ë³„": display_df = display_df.sort_values(by='ë°˜ì‘', ascending=False)
        elif sort_option == "ë ˆë²¨ ë†’ì€ ìˆœ": display_df = display_df.sort_values(by='ë ˆë²¨', ascending=False)

        st.caption(f"ì´ {len(display_df)}ê¶Œì˜ ì±…")

        for i, row in display_df.iterrows():
            with st.container():
                c1, c2 = st.columns([1, 5])
                with c1:
                    st.image(row['í‘œì§€URL'] if pd.notna(row['í‘œì§€URL']) and str(row['í‘œì§€URL']).startswith("http") else "https://via.placeholder.com/150", width=80)
                
                with c2:
                    st.markdown(f"#### **{row['ì œëª©']}**")
                    st.text(f"ISBN: {row['ISBN'] if pd.notna(row['ISBN']) else '-'}")

                    ec1, ec2, ec3 = st.columns([1, 1.2, 2.5])
                    
                    # ì‹¤ì œ ì¸ë±ìŠ¤ ì°¾ê¸°
                    real_idx = books_df[books_df['ID'] == row['ID']].index[0]

                    # ìˆ˜ì • ì»¨íŠ¸ë¡¤
                    cur_lvl = int(row['ë ˆë²¨'] - 1) if 1 <= row['ë ˆë²¨'] <= 5 else 0
                    with ec1: new_lvl = st.selectbox("ë ˆë²¨", [1,2,3,4,5], index=cur_lvl, key=f"l_{row['ID']}", label_visibility="collapsed")
                    
                    sts_opts = ["ì½ì§€ ì•ŠìŒ", "ì½ëŠ” ì¤‘", "ì™„ë…"]
                    try: s_idx = sts_opts.index(row['ìƒíƒœ'])
                    except: s_idx = 0
                    with ec2: new_sts = st.selectbox("ìƒíƒœ", sts_opts, index=s_idx, key=f"s_{row['ID']}", label_visibility="collapsed")
                    
                    try: r_idx = REACTION_OPTIONS.index(row['ë°˜ì‘'])
                    except: r_idx = 0
                    with ec3: new_react = st.selectbox("ë°˜ì‘", REACTION_OPTIONS, index=r_idx, key=f"r_{row['ID']}", label_visibility="collapsed")

                    # ìˆ˜ì • ì €ì¥
                    if new_lvl != row['ë ˆë²¨'] or new_sts != row['ìƒíƒœ'] or new_react != row['ë°˜ì‘']:
                        with st.spinner("ì €ì¥ ì¤‘..."):
                            books_df.at[real_idx, 'ë ˆë²¨'] = new_lvl
                            books_df.at[real_idx, 'ìƒíƒœ'] = new_sts
                            books_df.at[real_idx, 'ë°˜ì‘'] = new_react
                            save_books(books_df)
                        st.toast(f"âœ… ìˆ˜ì • ì™„ë£Œ!")
                        st.rerun()

                    # ìœ íŠœë¸Œ ë§í¬
                    search_query = f"{row['ì œëª©']} Audio file"
                    encoded_query = urllib.parse.quote(search_query)
                    youtube_url = f"https://www.youtube.com/results?search_query={encoded_query}"

                    # ë²„íŠ¼
                    b1, b2, b3 = st.columns([1.2, 1.2, 1])
                    if b1.button(f"â• ì½ê¸° ì¶”ê°€ ({int(row['ì½ì€íšŸìˆ˜'])}íšŒ)", key=f"btn_r_{row['ID']}"):
                        with st.spinner("ê¸°ë¡ ì¤‘..."):
                            books_df.at[real_idx, 'ì½ì€íšŸìˆ˜'] += 1
                            if books_df.at[real_idx, 'ìƒíƒœ'] == 'ì½ì§€ ì•ŠìŒ': books_df.at[real_idx, 'ìƒíƒœ'] = 'ì½ëŠ” ì¤‘'
                            save_books(books_df) # ìƒíƒœ ì €ì¥
                            add_log(row['ID'], row['ì œëª©'], new_lvl) # ë¡œê·¸ ì €ì¥
                        st.toast("ğŸ“– ë…ì„œ ê¸°ë¡ ì¶”ê°€ ì™„ë£Œ!")
                        st.rerun()

                    with b2:
                        st.link_button("ğŸ§ ì˜¤ë””ì˜¤ ì°¾ê¸°", youtube_url)

                    if b3.button("ğŸ—‘ ì‚­ì œ", key=f"btn_d_{row['ID']}"):
                        if st.session_state.get(f"del_confirm_{row['ID']}"):
                             with st.spinner("ì‚­ì œ ì¤‘..."):
                                books_df = books_df.drop(real_idx)
                                save_books(books_df)
                             st.rerun()
                        else:
                             st.session_state[f"del_confirm_{row['ID']}"] = True
                             st.warning("í•œ ë²ˆ ë” ëˆ„ë¥´ë©´ ì‚­ì œë©ë‹ˆë‹¤.")
                st.divider()
    else:
        st.info("ë“±ë¡ëœ ì±…ì´ ì—†ìŠµë‹ˆë‹¤.")

# --- [íƒ­ 3] ìƒˆ ì±… ë“±ë¡ ---
with tab3:
    st.subheader("ìƒˆë¡œìš´ ì±… ì…ê³ ")
    if 'auto_title' not in st.session_state: st.session_state.update({'auto_title':"", 'auto_isbn':"", 'auto_img':"", 'search_done':False})

    input_method = st.radio("ì…ë ¥ ë°©ì‹", ["ğŸ“¸ ë°”ì½”ë“œ ìŠ¤ìº”", "ğŸ“‚ ì‚¬ì§„ ì—…ë¡œë“œ (ì¶”ì²œ)", "âœï¸ ìˆ˜ë™ ì…ë ¥"], horizontal=True)
    
    img_file = None 
    if input_method == "ğŸ“¸ ë°”ì½”ë“œ ìŠ¤ìº”":
        st.info("ğŸ’¡ íŒ: ì´ˆì ì´ ì•ˆ ë§ìœ¼ë©´ 30cm ì´ìƒ ë–¼ê³  ì´¬ì˜í•˜ì„¸ìš”.")
        img_file = st.camera_input("ë°”ì½”ë“œ ì´¬ì˜")
    elif input_method == "ğŸ“‚ ì‚¬ì§„ ì—…ë¡œë“œ (ì¶”ì²œ)":
        st.info("ğŸ’¡ í° ì¹´ë©”ë¼ë¡œ ì°ì€ ì„ ëª…í•œ ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
        img_file = st.file_uploader("ë°”ì½”ë“œ ì‚¬ì§„ ì„ íƒ", type=['png', 'jpg', 'jpeg'])

    if img_file and not st.session_state.get('search_done'):
        isbn_val = scan_barcode(img_file)
        if isbn_val:
            st.toast(f"ğŸ‰ ì¸ì‹ ì„±ê³µ: {isbn_val}")
            if st.session_state['auto_isbn'] != isbn_val:
                with st.spinner("ì •ë³´ ê²€ìƒ‰ ì¤‘..."):
                    t, i = search_book_info(isbn_val)
                    st.session_state.update({'auto_isbn': isbn_val, 'auto_title': t or "", 'auto_img': i or "", 'search_done': True})
                    st.rerun()
        else:
            st.error("ë°”ì½”ë“œ ì¸ì‹ ì‹¤íŒ¨.")

    if input_method == "âœï¸ ìˆ˜ë™ ì…ë ¥":
        manual_isbn = st.text_input("ISBN ì§ì ‘ ì…ë ¥", value=st.session_state['auto_isbn'])
        if manual_isbn and manual_isbn != st.session_state.get('last_manual', ''):
             with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                t, i = search_book_info(manual_isbn)
                st.session_state.update({'auto_isbn': manual_isbn, 'auto_title': t or "", 'auto_img': i or "", 'last_manual': manual_isbn})
                st.rerun()

    st.divider()

    with st.form("reg_form", clear_on_submit=True):
        c1, c2 = st.columns(2)
        with c1:
            title = st.text_input("ì±… ì œëª©", value=st.session_state['auto_title'])
            isbn = st.text_input("ISBN", value=st.session_state['auto_isbn'])
            level = st.selectbox("ë ˆë²¨", [1,2,3,4,5])
        with c2:
            img_url = st.text_input("í‘œì§€ URL", value=st.session_state['auto_img'])
            if img_url: st.image(img_url, width=80)
            status = st.selectbox("ìƒíƒœ", ["ì½ì§€ ì•ŠìŒ", "ì½ëŠ” ì¤‘", "ì™„ë…"])
            reaction = st.selectbox("ì•„ì´ ë°˜ì‘", REACTION_OPTIONS)
            
        if st.form_submit_button("ë“±ë¡í•˜ê¸°"):
            if not title:
                st.error("ì œëª©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
            else:
                with st.spinner("êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ ì¤‘..."):
                    new_data = {
                        'ID': str(uuid.uuid4()), 'ì œëª©': title, 'ISBN': isbn, 'ë ˆë²¨': level, 
                        'ì½ì€íšŸìˆ˜': 0, 'ìƒíƒœ': status, 'ë°˜ì‘': reaction, 'í‘œì§€URL': img_url
                    }
                    books_df = pd.concat([books_df, pd.DataFrame([new_data])], ignore_index=True)
                    save_books(books_df)
                    
                    for key in ['auto_title', 'auto_isbn', 'auto_img', 'search_done', 'last_manual']:
                        if key in st.session_state: del st.session_state[key]
                st.success("ë“±ë¡ ì™„ë£Œ!")
                st.rerun()
