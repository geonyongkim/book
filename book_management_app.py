import streamlit as st
import pandas as pd
import uuid
import requests
import urllib.parse
from PIL import Image, ImageEnhance
from pyzbar.pyzbar import decode
from datetime import datetime, timedelta
import plotly.express as px

# [Google Sheets ì—°ë™ ë¼ì´ë¸ŒëŸ¬ë¦¬]
import gspread
from google.oauth2.service_account import Credentials

# =========================================================
# ğŸš¨ [í•„ìˆ˜ ì„¤ì •] ì•„ë˜ ì£¼ì†Œë¥¼ ì‚¬ìš©ìë‹˜ì˜ êµ¬ê¸€ ì‹œíŠ¸ ì£¼ì†Œë¡œ ë°”ê¿”ì£¼ì„¸ìš”!
# =========================================================
SHEET_URL = "https://docs.google.com/spreadsheets/d/1WyA_dM3_cxqurORJ1wbYACBFBgDG9-4b_wPk8nWbwhA/edit?gid=1353177291#gid=1353177291" 
# (ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ì— ìˆëŠ” ë§í¬ë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ìœ„ ë”°ì˜´í‘œ ì•ˆì— ë„£ìœ¼ì„¸ìš”)

# --- [ë°˜ì‘ ì˜µì…˜ ì •ì˜] ---
REACTION_OPTIONS = ["ì„ íƒ ì•ˆ í•¨", "ğŸ˜„ ì¬ë¯¸ìˆì–´ìš”", "ğŸ˜“ ì–´ë ¤ì›Œìš”", "ğŸ¨ ê·¸ë¦¼ì´ ë§ˆìŒì— ë“¤ì–´ìš”", "ğŸ£ ìŠ¤ìŠ¤ë¡œ ì½ì„ ìˆ˜ ìˆì–´ìš”"]

# --- [í•¨ìˆ˜ 1] êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ---
@st.cache_resource
def get_google_sheet_client():
    scopes = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ]
    credentials = Credentials.from_service_account_info(
        st.secrets["gcp_service_account"],
        scopes=scopes
    )
    client = gspread.authorize(credentials)
    return client

# --- [í•¨ìˆ˜ 2] ë°ì´í„° ë¡œë“œ (URLë¡œ ì ‘ì†) ---
def load_data():
    client = get_google_sheet_client()
    try:
        # [ë³€ê²½] ì´ë¦„ ëŒ€ì‹  URLë¡œ ì—½ë‹ˆë‹¤ (ì˜¤ë¥˜ í•´ê²°ì˜ í•µì‹¬)
        sh = client.open_by_url(SHEET_URL)
    except gspread.exceptions.APIError:
        st.error("âŒ êµ¬ê¸€ ì‹œíŠ¸ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì´ ì •í™•í•œì§€, ì„œë¹„ìŠ¤ ê³„ì •ì´ 'í¸ì§‘ì'ë¡œ ì´ˆëŒ€ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    except gspread.exceptions.NoValidUrlKeyFound:
        st.error("âŒ URL í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. êµ¬ê¸€ ì‹œíŠ¸ ì£¼ì†Œë¥¼ ì „ì²´ ë³µì‚¬í•´ì„œ ë„£ì–´ì£¼ì„¸ìš”.")
        st.stop()

    # 1. Books ë°ì´í„° ë¡œë“œ
    try:
        wks_books = sh.worksheet("books")
        data_books = wks_books.get_all_records()
        books_df = pd.DataFrame(data_books)
        
        required_cols = ['ID', 'ì œëª©', 'ISBN', 'ë ˆë²¨', 'ì½ì€íšŸìˆ˜', 'ìƒíƒœ', 'ë°˜ì‘', 'í‘œì§€URL']
        if books_df.empty:
            books_df = pd.DataFrame(columns=required_cols)
        else:
            for col in required_cols:
                if col not in books_df.columns:
                    books_df[col] = ""
            # NaN ì²˜ë¦¬
            books_df['ë°˜ì‘'] = books_df['ë°˜ì‘'].replace("", "ì„ íƒ ì•ˆ í•¨").fillna("ì„ íƒ ì•ˆ í•¨")
            books_df['ISBN'] = books_df['ISBN'].astype(str)
            
    except gspread.exceptions.WorksheetNotFound:
        wks_books = sh.add_worksheet(title="books", rows=100, cols=10)
        wks_books.append_row(['ID', 'ì œëª©', 'ISBN', 'ë ˆë²¨', 'ì½ì€íšŸìˆ˜', 'ìƒíƒœ', 'ë°˜ì‘', 'í‘œì§€URL'])
        books_df = pd.DataFrame(columns=['ID', 'ì œëª©', 'ISBN', 'ë ˆë²¨', 'ì½ì€íšŸìˆ˜', 'ìƒíƒœ', 'ë°˜ì‘', 'í‘œì§€URL'])

    # 2. Logs ë°ì´í„° ë¡œë“œ
    try:
        wks_logs = sh.worksheet("logs")
        data_logs = wks_logs.get_all_records()
        logs_df = pd.DataFrame(data_logs)
        
        if logs_df.empty:
            logs_df = pd.DataFrame(columns=['ë‚ ì§œ', 'ì±…ID', 'ì œëª©', 'ë ˆë²¨'])
        else:
            logs_df['ë‚ ì§œ'] = pd.to_datetime(logs_df['ë‚ ì§œ'])
            
    except gspread.exceptions.WorksheetNotFound:
        wks_logs = sh.add_worksheet(title="logs", rows=100, cols=5)
        wks_logs.append_row(['ë‚ ì§œ', 'ì±…ID', 'ì œëª©', 'ë ˆë²¨'])
        logs_df = pd.DataFrame(columns=['ë‚ ì§œ', 'ì±…ID', 'ì œëª©', 'ë ˆë²¨'])

    return books_df, logs_df

# --- [í•¨ìˆ˜ 3] ë°ì´í„° ì €ì¥ (URLë¡œ ì ‘ì†) ---
def save_books(df):
    client = get_google_sheet_client()
    sh = client.open_by_url(SHEET_URL) # [ë³€ê²½]
    wks = sh.worksheet("books")
    
    header = df.columns.values.tolist()
    data = df.fillna("").values.tolist()
    
    wks.clear()
    wks.update(range_name='A1', values=[header] + data)

# --- [í•¨ìˆ˜ 4] ë¡œê·¸ ì¶”ê°€ (URLë¡œ ì ‘ì†) ---
def add_log(book_id, title, level):
    client = get_google_sheet_client()
    sh = client.open_by_url(SHEET_URL) # [ë³€ê²½]
    wks = sh.worksheet("logs")
    
    today_str = datetime.now().strftime("%Y-%m-%d")
    wks.append_row([today_str, str(book_id), str(title), int(level)])

# --- [í•¨ìˆ˜ 5] ë°”ì½”ë“œ ìŠ¤ìº” ---
def scan_barcode(image_file):
    try:
        image = Image.open(image_file)
        attempts = [
            image.convert('L'), 
            image.convert('L').crop((image.size[0]*0.2, image.size[1]*0.2, image.size[0]*0.8, image.size[1]*0.8)),
            ImageEnhance.Sharpness(image.convert('L').crop((image.size[0]*0.35, image.size[1]*0.35, image.size[0]*0.65, image.size[1]*0.65))).enhance(2.0)
        ]
        for img in attempts:
            decoded = decode(img)
            for obj in decoded: return obj.data.decode("utf-8")
    except Exception: pass
    return None

# --- [í•¨ìˆ˜ 6] ë„ì„œ ê²€ìƒ‰ ---
def search_book_info(isbn):
    if not isbn: return None, None
    clean_isbn = str(isbn).strip().replace("-", "").replace(" ", "")
    try:
        r = requests.get(f"https://www.googleapis.com/books/v1/volumes?q=isbn:{clean_isbn}").json()
        if "items" in r:
            return r["items"][0]["volumeInfo"].get("title", ""), r["items"][0]["volumeInfo"].get("imageLinks", {}).get("thumbnail", "")
    except: pass
    try:
        r = requests.get(f"https://openlibrary.org/api/books?bibkeys=ISBN:{clean_isbn}&jscmd=data&format=json").json()
        if f"ISBN:{clean_isbn}" in r:
            bk = r[f"ISBN:{clean_isbn}"]
            cv = bk.get("cover", {})
            return bk.get("title", ""), (cv.get("medium") or cv.get("large") or cv.get("small", ""))
    except: pass
    return None, None

# =========================================================
# ë©”ì¸ UI
# =========================================================

st.set_page_config(page_title="ì•„ì´ ì˜ì–´ ë…ì„œ ë§¤ë‹ˆì € (Cloud)", layout="wide", page_icon="â˜ï¸")

# ë°ì´í„° ë¡œë“œ
with st.spinner("êµ¬ê¸€ ì‹œíŠ¸ì™€ ì—°ê²° ì¤‘..."):
    books_df, logs_df = load_data()

st.title("ğŸ“š Smart English Library v3.1")
st.caption("êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì™€ ì‹¤ì‹œê°„ ì—°ë™ë©ë‹ˆë‹¤.")

tab1, tab2, tab3 = st.tabs(["ğŸ“Š ìƒì„¸ ëŒ€ì‹œë³´ë“œ", "ğŸ“– ì„œì¬ ê´€ë¦¬", "â• ìƒˆ ì±… ë“±ë¡"])

# --- [íƒ­ 1] ìƒì„¸ ëŒ€ì‹œë³´ë“œ ---
with tab1:
    st.markdown("### ğŸ“ˆ ë…ì„œ í˜„í™© ë¸Œë¦¬í•‘")
    if logs_df.empty and books_df.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì±…ì„ ë“±ë¡í•´ì£¼ì„¸ìš”.")
    else:
        today = pd.Timestamp.now().normalize()
        this_month_start = today.replace(day=1)
        
        daily_reads = logs_df[logs_df['ë‚ ì§œ'] == today]
        month_reads = logs_df[logs_df['ë‚ ì§œ'] >= this_month_start]
        
        kpi1, kpi2, kpi3, kpi4 = st.columns(4)
        kpi1.metric("ì´ ë³´ìœ  ë„ì„œ", f"{len(books_df)}ê¶Œ")
        kpi2.metric("ì´ ëˆ„ì  ì½ê¸°", f"{len(logs_df)}íšŒ")
        kpi3.metric("ì´ë²ˆ ë‹¬ ë…ì„œ", f"{len(month_reads)}íšŒ")
        kpi4.metric("ì˜¤ëŠ˜ ì½ì€ ì±…", f"{len(daily_reads)}ê¶Œ")
        st.divider()
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.subheader("ğŸ—“ï¸ ìµœê·¼ 30ì¼ ë…ì„œ")
            if not logs_df.empty:
                last_30 = logs_df[logs_df['ë‚ ì§œ'] >= (today - timedelta(days=29))]
                daily_counts = last_30.groupby('ë‚ ì§œ').size().reset_index(name='ê¶Œìˆ˜')
                fig = px.bar(daily_counts, x='ë‚ ì§œ', y='ê¶Œìˆ˜', text_auto=True, color_discrete_sequence=['#4C78A8'])
                st.plotly_chart(fig, use_container_width=True)
        with c2:
            st.subheader("ğŸ§¸ ì•„ì´ ë°˜ì‘")
            if not books_df.empty:
                reaction_counts = books_df[books_df['ë°˜ì‘'] != 'ì„ íƒ ì•ˆ í•¨']['ë°˜ì‘'].value_counts().reset_index()
                reaction_counts.columns = ['ë°˜ì‘', 'ê¶Œìˆ˜']
                if not reaction_counts.empty:
                    fig2 = px.pie(reaction_counts, values='ê¶Œìˆ˜', names='ë°˜ì‘', hole=0.4)
                    st.plotly_chart(fig2, use_container_width=True)
        st.divider()

        r1, r2 = st.columns(2)
        with r1:
            st.subheader("ğŸ† Top 5 ì½ì€ ì±…")
            if not books_df.empty:
                books_df['ì½ì€íšŸìˆ˜'] = pd.to_numeric(books_df['ì½ì€íšŸìˆ˜'], errors='coerce').fillna(0)
                top_books = books_df.sort_values(by='ì½ì€íšŸìˆ˜', ascending=False).head(5)
                for idx, row in top_books.iterrows():
                    st.write(f"**{int(row['ì½ì€íšŸìˆ˜'])}íšŒ** | {row['ì œëª©']} (Lv.{row['ë ˆë²¨']})")
        with r2:
            st.subheader("ğŸ“š ë ˆë²¨ë³„ ë³´ìœ ")
            if not books_df.empty:
                lvl_counts = books_df['ë ˆë²¨'].value_counts().sort_index()
                st.bar_chart(lvl_counts)

# --- [íƒ­ 2] ì„œì¬ ê´€ë¦¬ ---
with tab2:
    c_head, c_sort = st.columns([3, 2])
    with c_head: st.subheader("ë³´ìœ  ë„ì„œ ê´€ë¦¬")
    with c_sort:
        sort_option = st.selectbox("ì •ë ¬", ["ìµœì‹  ë“±ë¡ìˆœ", "ìì£¼ ì½ì€ ì±…", "ì•ˆ ì½ì€ ì±…", "ì•„ì´ ë°˜ì‘ë³„", "ë ˆë²¨ ë†’ì€ ìˆœ"])

    if not books_df.empty:
        books_df['ì½ì€íšŸìˆ˜'] = pd.to_numeric(books_df['ì½ì€íšŸìˆ˜'], errors='coerce').fillna(0)
        books_df['ë ˆë²¨'] = pd.to_numeric(books_df['ë ˆë²¨'], errors='coerce').fillna(1)
        display_df = books_df.copy()
        
        if sort_option == "ìµœì‹  ë“±ë¡ìˆœ": display_df = display_df.iloc[::-1]
        elif sort_option == "ìì£¼ ì½ì€ ì±…": display_df = display_df.sort_values(by='ì½ì€íšŸìˆ˜', ascending=False)
        elif sort_option == "ì•ˆ ì½ì€ ì±…": display_df = display_df.sort_values(by='ì½ì€íšŸìˆ˜', ascending=True)
        elif sort_option == "ì•„ì´ ë°˜ì‘ë³„": display_df = display_df.sort_values(by='ë°˜ì‘', ascending=False)
        elif sort_option == "ë ˆë²¨ ë†’ì€ ìˆœ": display_df = display_df.sort_values(by='ë ˆë²¨', ascending=False)

        st.caption(f"ì´ {len(display_df)}ê¶Œ")

        for i, row in display_df.iterrows():
            with st.container():
                c1, c2 = st.columns([1, 5])
                with c1: st.image(row['í‘œì§€URL'] if pd.notna(row['í‘œì§€URL']) and str(row['í‘œì§€URL']).startswith("http") else "https://via.placeholder.com/150", width=80)
                with c2:
                    st.markdown(f"#### **{row['ì œëª©']}**")
                    st.text(f"ISBN: {row['ISBN']}")

                    ec1, ec2, ec3 = st.columns([1, 1.2, 2.5])
                    real_idx = books_df[books_df['ID'] == row['ID']].index[0]

                    with ec1: new_lvl = st.selectbox("ë ˆë²¨", [1,2,3,4,5], index=int(row['ë ˆë²¨'])-1, key=f"l_{row['ID']}", label_visibility="collapsed")
                    with ec2: 
                        s_idx = ["ì½ì§€ ì•ŠìŒ", "ì½ëŠ” ì¤‘", "ì™„ë…"].index(row['ìƒíƒœ']) if row['ìƒíƒœ'] in ["ì½ì§€ ì•ŠìŒ", "ì½ëŠ” ì¤‘", "ì™„ë…"] else 0
                        new_sts = st.selectbox("ìƒíƒœ", ["ì½ì§€ ì•ŠìŒ", "ì½ëŠ” ì¤‘", "ì™„ë…"], index=s_idx, key=f"s_{row['ID']}", label_visibility="collapsed")
                    with ec3:
                        r_idx = REACTION_OPTIONS.index(row['ë°˜ì‘']) if row['ë°˜ì‘'] in REACTION_OPTIONS else 0
                        new_react = st.selectbox("ë°˜ì‘", REACTION_OPTIONS, index=r_idx, key=f"r_{row['ID']}", label_visibility="collapsed")

                    if new_lvl != row['ë ˆë²¨'] or new_sts != row['ìƒíƒœ'] or new_react != row['ë°˜ì‘']:
                        with st.spinner("ì €ì¥ ì¤‘..."):
                            books_df.at[real_idx, 'ë ˆë²¨'] = new_lvl
                            books_df.at[real_idx, 'ìƒíƒœ'] = new_sts
                            books_df.at[real_idx, 'ë°˜ì‘'] = new_react
                            save_books(books_df)
                        st.toast(f"âœ… ìˆ˜ì • ì™„ë£Œ")
                        st.rerun()

                    search_query = f"{row['ì œëª©']} read a loud"
                    youtube_url = f"https://www.youtube.com/results?search_query={urllib.parse.quote(search_query)}"

                    b1, b2, b3 = st.columns([1.2, 1.2, 1])
                    if b1.button(f"â• ì½ê¸° ì¶”ê°€ ({int(row['ì½ì€íšŸìˆ˜'])})", key=f"btn_r_{row['ID']}"):
                        with st.spinner("ê¸°ë¡ ì¤‘..."):
                            books_df.at[real_idx, 'ì½ì€íšŸìˆ˜'] += 1
                            if books_df.at[real_idx, 'ìƒíƒœ'] == 'ì½ì§€ ì•ŠìŒ': books_df.at[real_idx, 'ìƒíƒœ'] = 'ì½ëŠ” ì¤‘'
                            save_books(books_df)
                            add_log(row['ID'], row['ì œëª©'], new_lvl)
                        st.toast("ğŸ“– ê¸°ë¡ ì™„ë£Œ")
                        st.rerun()
                    with b2: st.link_button("ğŸ§ ì˜¤ë””ì˜¤ ì°¾ê¸°", youtube_url)
                    if b3.button("ğŸ—‘ ì‚­ì œ", key=f"btn_d_{row['ID']}"):
                        if st.session_state.get(f"del_{row['ID']}"):
                             with st.spinner("ì‚­ì œ ì¤‘..."):
                                books_df = books_df.drop(real_idx)
                                save_books(books_df)
                             st.rerun()
                        else:
                             st.session_state[f"del_{row['ID']}"] = True
                             st.warning("ì‚­ì œ í™•ì¸")
                st.divider()
    else: st.info("ë“±ë¡ëœ ì±… ì—†ìŒ")

# --- [íƒ­ 3] ìƒˆ ì±… ë“±ë¡ ---
with tab3:
    st.subheader("ìƒˆ ì±… ì…ê³ ")
    if 'auto_title' not in st.session_state: st.session_state.update({'auto_title':"", 'auto_isbn':"", 'auto_img':"", 'search_done':False})

    input_method = st.radio("ì…ë ¥ ë°©ì‹", ["ğŸ“¸ ë°”ì½”ë“œ ìŠ¤ìº”", "ğŸ“‚ ì‚¬ì§„ ì—…ë¡œë“œ", "âœï¸ ìˆ˜ë™ ì…ë ¥"], horizontal=True)
    
    img_file = None 
    if input_method == "ğŸ“¸ ë°”ì½”ë“œ ìŠ¤ìº”": img_file = st.camera_input("ë°”ì½”ë“œ ì´¬ì˜")
    elif input_method == "ğŸ“‚ ì‚¬ì§„ ì—…ë¡œë“œ": img_file = st.file_uploader("ì‚¬ì§„ ì„ íƒ", type=['png', 'jpg', 'jpeg'])

    if img_file and not st.session_state.get('search_done'):
        isbn_val = scan_barcode(img_file)
        if isbn_val:
            st.toast(f"ì¸ì‹ ì„±ê³µ: {isbn_val}")
            if st.session_state['auto_isbn'] != isbn_val:
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    t, i = search_book_info(isbn_val)
                    st.session_state.update({'auto_isbn': isbn_val, 'auto_title': t or "", 'auto_img': i or "", 'search_done': True})
                    st.rerun()
        else: st.error("ì¸ì‹ ì‹¤íŒ¨")

    if input_method == "âœï¸ ìˆ˜ë™ ì…ë ¥":
        manual_isbn = st.text_input("ISBN ì…ë ¥", value=st.session_state['auto_isbn'])
        if manual_isbn and manual_isbn != st.session_state.get('last_manual', ''):
             with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                t, i = search_book_info(manual_isbn)
                st.session_state.update({'auto_isbn': manual_isbn, 'auto_title': t or "", 'auto_img': i or "", 'last_manual': manual_isbn})
                st.rerun()
    st.divider()

    with st.form("reg_form", clear_on_submit=True):
        c1, c2 = st.columns(2)
        with c1:
            title = st.text_input("ì œëª©", value=st.session_state['auto_title'])
            isbn = st.text_input("ISBN", value=st.session_state['auto_isbn'])
            level = st.selectbox("ë ˆë²¨", [1,2,3,4,5])
        with c2:
            img_url = st.text_input("í‘œì§€ URL", value=st.session_state['auto_img'])
            status = st.selectbox("ìƒíƒœ", ["ì½ì§€ ì•ŠìŒ", "ì½ëŠ” ì¤‘", "ì™„ë…"])
            reaction = st.selectbox("ë°˜ì‘", REACTION_OPTIONS)
            
        if st.form_submit_button("ë“±ë¡í•˜ê¸°"):
            if not title: st.error("ì œëª© í•„ìˆ˜")
            else:
                with st.spinner("ì €ì¥ ì¤‘..."):
                    new_data = {'ID': str(uuid.uuid4()), 'ì œëª©': title, 'ISBN': isbn, 'ë ˆë²¨': level, 'ì½ì€íšŸìˆ˜': 0, 'ìƒíƒœ': status, 'ë°˜ì‘': reaction, 'í‘œì§€URL': img_url}
                    books_df = pd.concat([books_df, pd.DataFrame([new_data])], ignore_index=True)
                    save_books(books_df)
                    for key in ['auto_title', 'auto_isbn', 'auto_img', 'search_done', 'last_manual']:
                        if key in st.session_state: del st.session_state[key]
                st.success("ì™„ë£Œ!")
                st.rerun()
